{"file": {"path": "/Users/dakixr/Desktop/github/scc/tmp-data/metadata/KnowledgeCaptureAndDiscoveryANDmintproject/P4ML-UI/dsbox-corex/LinearCorex/linearcorex/linearcorex.py", "fileNameBase": "linearcorex", "extension": "py", "doc": {"long_description": "Recovers linear latent factors from data, like PCA/ICA/FA, etc. except that\nthese factors are maximally informative about relationships in the data.\nWe also constrain our solutions to be \"non-synergistic\" for better interpretability.\n(That is the TC(Y|Xi)=0 constraint in the \"blessing of dimensionality\" paper.)\n\nCode below written by:\nGreg Ver Steeg (gregv@isi.edu), 2017.", "short_description": "Linear Total Correlation Explanation", "full": "Linear Total Correlation Explanation\nRecovers linear latent factors from data, like PCA/ICA/FA, etc. except that\nthese factors are maximally informative about relationships in the data.\nWe also constrain our solutions to be \"non-synergistic\" for better interpretability.\n(That is the TC(Y|Xi)=0 constraint in the \"blessing of dimensionality\" paper.)\n\nCode below written by:\nGreg Ver Steeg (gregv@isi.edu), 2017."}}, "dependencies": [{"import": "numpy", "alias": "np", "type": "external"}, {"from_module": "scipy.stats", "import": "norm", "type": "external"}, {"from_module": "scipy.stats", "import": "rankdata", "type": "external"}, {"import": "gc", "type": "external"}], "classes": {"Corex": {"doc": {"long_description": "Conventions\n----------\nCode follows sklearn naming/style (e.g. fit(X) to train, transform() to apply model to test data).", "short_description": "Linear Total Correlation Explanation", "full": "Linear Total Correlation Explanation\n\nConventions\n----------\nCode follows sklearn naming/style (e.g. fit(X) to train, transform() to apply model to test data).\n\nParameters\n----------\nn_hidden : int, default = 2\n    The number of latent factors to use.\n\nmax_iter : int, default = 10000\n    The max. number of iterations to reach convergence.\n\ntol : float, default = 0.0001\n    Used to test for convergence.\n\neliminate_synergy : bool, default = True\n    Use a constraint that the information latent factors have about data is not synergistic.\n\ngaussianize : str, default = 'standard'\n    Preprocess data so each marginal is near a standard normal. See gaussianize method for more details.\n\nyscale : float default = 1\n    We imagine some small fundamental measurement noise on Y. The value is arbitrary, but it sets\n    the scale of the results, Y.\n\nverbose : int, optional\n    Print verbose outputs.\n\nseed : integer or numpy.RandomState, optional\n    A random number generator instance to define the state of the\n    random permutations generator. If an integer is given, it fixes the\n    seed. Defaults to the global numpy random number generator.\n\nAttributes\n----------\n\n\nReferences\n----------\n[1] Greg Ver Steeg and Aram Galstyan. \"Maximally Informative Hierarchical...\", AISTATS 2015.\n[2] Greg Ver Steeg, Shuyang Gao, Kyle Reing, and Aram Galstyan. \"Sifting Common Information from Many Variables\",\n                                                                IJCAI 2017.\n[3] Greg Ver Steeg and Aram Galstyan. \"Low Complexity Gaussian Latent Factor Models and\n                                       a Blessing of Dimensionality\", 2017."}, "extend": ["object"], "min_max_lineno": {"min_lineno": 22, "max_lineno": 446}, "methods": {"__init__": {"args": ["self", "n_hidden", "max_iter", "tol", "anneal", "missing_values", "discourage_overlap", "gaussianize", "gpu", "verbose", "seed"], "min_max_lineno": {"min_lineno": 72, "max_lineno": 102}, "calls": ["numpy.random.seed", "numpy.zeros", "cm.cublas_init", "numpy.set_printoptions", "print"], "store_vars_calls": {"self.ws": "np.zeros"}}, "fit_transform": {"args": ["self", "x"], "min_max_lineno": {"min_lineno": 103, "max_lineno": 106}, "calls": ["linearcorex.Corex.fit", "linearcorex.Corex.transform"]}, "fit": {"args": ["self", "x"], "returns": [["self"], ["self"]], "min_max_lineno": {"min_lineno": 107, "max_lineno": 162}, "calls": ["numpy.asarray", "linearcorex.Corex.preprocess", "linearcorex.Corex._calculate_moments", "enumerate", "linearcorex.Corex._calculate_moments", "numpy.argsort", "linearcorex.Corex._calculate_moments", "linearcorex.pick_n_hidden", "linearcorex.Corex._calculate_moments", "range", "numpy.random.randn().astype", "numpy.sum", "numpy.abs", "linearcorex.Corex.update_records", "numpy.sqrt", "numpy.sqrt", "linearcorex.Corex._update_ns", "linearcorex.Corex._update_syn", "print", "numpy.random.randn", "linearcorex.Corex._norm", "numpy.random.randn", "numpy.isfinite", "print", "print", "print", "numpy.abs.sum", "range"], "store_vars_calls": {"x": "self.preprocess", "self.moments": "self._calculate_moments", "order": "np.argsort", "self.m": "pick_n_hidden", "self.ws": "np.random.randn().astype", "wmag": "np.sum", "delta": "np.abs"}}, "update_records": {"doc": {"short_description": "Print and store some statistics about each iteration."}, "args": ["self", "moments", "delta"], "min_max_lineno": {"min_lineno": 163, "max_lineno": 173}, "calls": ["gc.disable", "gc.enable", "linearcorex.Corex.history.get", "print", "linearcorex.Corex.history.get", "linearcorex.Corex.history.get", "moments.get", "moments.get", "moments.get", "numpy.zeros"]}, "tc": {"doc": {"long_description": "would be satisfied by a non-overlapping model.\nCheck \"moments\" for two other estimates of TC that may be useful.", "short_description": "This actually returns the lower bound on TC that is optimized. The lower bound assumes a constraint that"}, "args": ["self"], "min_max_lineno": {"min_lineno": 174, "max_lineno": 180}}, "tcs": {"doc": {"short_description": "TCs for each individual latent factor. They DO NOT sum to TC in this case, because of overlaps."}, "args": ["self"], "min_max_lineno": {"min_lineno": 181, "max_lineno": 185}}, "mis": {"args": ["self"], "min_max_lineno": {"min_lineno": 186, "max_lineno": 189}, "calls": ["numpy.log1p"]}, "clusters": {"args": ["self"], "min_max_lineno": {"min_lineno": 190, "max_lineno": 192}, "calls": ["numpy.argmax", "numpy.abs"]}, "_sig": {"doc": {"long_description": "n_variables >> n_samples, so we do this without explicitly constructing the covariance matrix.", "short_description": "Multiple the matrix u by the covariance matrix of x. We are interested in situations where"}, "args": ["self", "x", "u"], "returns": [["prod"]], "min_max_lineno": {"min_lineno": 193, "max_lineno": 211}, "calls": ["cm.empty", "cm.CUDAMatrix", "cm.dot", "cm.empty", "cm.dot", "cm.empty.asarray", "x.dot", "x.T.dot"], "store_vars_calls": {"y": "x.dot", "uc": "cm.CUDAMatrix", "tmp": "cm.empty", "tmp_dot": "x.T.dot"}}, "_norm": {"doc": {"short_description": "Calculate uj so that we can normalize it."}, "args": ["self", "x", "ws"], "min_max_lineno": {"min_lineno": 212, "max_lineno": 226}, "calls": ["numpy.sqrt", "cm.empty", "cm.CUDAMatrix", "cm.dot", "x.dot.asarray", "numpy.einsum", "x.dot", "numpy.einsum", "numpy.sum"], "store_vars_calls": {"y": "x.dot", "wc": "cm.CUDAMatrix", "y_local": "y.asarray", "tmp_sum": "np.einsum"}}, "_calculate_moments": {"args": ["self", "x", "ws", "quick"], "min_max_lineno": {"min_lineno": 227, "max_lineno": 232}, "calls": ["linearcorex.Corex._calculate_moments_ns", "linearcorex.Corex._calculate_moments_syn"]}, "_calculate_moments_ns": {"doc": {"long_description": "the value of the objective. Note it is assumed that <X_i^2> = 1!", "short_description": "Calculate moments based on the weights and samples. We also calculate and save MI, TC, additivity, and"}, "args": ["self", "x", "ws", "quick"], "returns": [["m"]], "min_max_lineno": {"min_lineno": 233, "max_lineno": 285}, "calls": ["ws.dot", "numpy.fill_diagonal", "numpy.dot", "numpy.einsum", "numpy.sum", "cm.empty", "cm.CUDAMatrix", "cm.dot", "numpy.einsum", "x.dot", "numpy.einsum", "cm.empty", "cm.dot", "cm.empty.asarray", "x.T.dot", "x.dot.asarray", "x.dot.asarray", "numpy.sum", "numpy.max", "numpy.sum", "numpy.sum", "numpy.log1p", "numpy.sqrt", "numpy.linalg.solve", "numpy.log", "m[].sum", "m[].max().sum", "m[].sum", "m[].sum", "numpy.log", "numpy.sum", "numpy.log", "numpy.log", "numpy.log", "numpy.log", "numpy.einsum", "m[].max", "m[].sum"], "store_vars_calls": {"y": "x.dot", "wc": "cm.CUDAMatrix", "tmp_sum": "np.einsum", "tmp": "cm.empty", "tmp_dot": "x.T.dot"}}, "_update_ns": {"doc": {"short_description": "Perform one update of the weights and re-calculate moments in the NON-SYNERGISTIC case."}, "args": ["self", "x"], "returns": [["w_update", "m_update"]], "min_max_lineno": {"min_lineno": 286, "max_lineno": 325}, "calls": ["numpy.dot", "numpy.fill_diagonal", "numpy.dot", "linearcorex.Corex._sig", "numpy.sum", "numpy.where", "numpy.einsum", "linearcorex.Corex._calculate_moments_ns", "min", "print", "print", "print"], "store_vars_calls": {"H": "np.dot", "sig_grad": "self._sig", "Bj": "np.sum", "update": "np.where", "update_tangent": "np.einsum", "m_update": "self._calculate_moments_ns"}}, "_calculate_moments_syn": {"doc": {"long_description": "the value of the objective. Note it is assumed that <X_i^2> = 1!", "short_description": "Calculate moments based on the weights and samples. We also calculate and save MI, TC, additivity, and"}, "args": ["self", "x", "ws", "quick"], "returns": [["m"]], "min_max_lineno": {"min_lineno": 326, "max_lineno": 364}, "calls": ["numpy.diag().copy", "numpy.dot", "numpy.einsum", "numpy.sum", "cm.empty", "cm.CUDAMatrix", "cm.dot", "x.dot", "cm.empty", "cm.dot", "ws.dot", "numpy.log1p", "numpy.linalg.solve", "numpy.log", "m[].sum", "numpy.sum", "numpy.sum", "cm.empty.asarray", "x.T.dot", "numpy.eye", "numpy.diag", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.log", "numpy.log", "numpy.einsum", "m[].sum"], "store_vars_calls": {"y": "x.dot", "wc": "cm.CUDAMatrix", "tmp_dot": "cm.empty"}}, "_update_syn": {"doc": {"short_description": "Perform one update of the weights and re-calculate moments in the SYNERGISTIC case."}, "args": ["self", "x", "eta"], "returns": [["ws", "m"]], "min_max_lineno": {"min_lineno": 365, "max_lineno": 375}, "calls": ["numpy.fill_diagonal", "numpy.dot", "linearcorex.Corex._calculate_moments_syn"], "store_vars_calls": {"S": "np.dot", "m": "self._calculate_moments_syn"}}, "transform": {"doc": {"long_description": "Optionally, you can get the remainder information and/or stop at a specified level.", "short_description": "Transform an array of inputs, x, into an array of k latent factors, Y."}, "args": ["self", "x", "details"], "returns": [["moments"]], "min_max_lineno": {"min_lineno": 376, "max_lineno": 386}, "calls": ["linearcorex.Corex.preprocess", "linearcorex.Corex.dot", "linearcorex.Corex._calculate_moments", "linearcorex.Corex.dot"], "store_vars_calls": {"x": "self.preprocess", "moments": "self._calculate_moments"}}, "preprocess": {"doc": {"long_description": "'standard' (default) just subtracts the mean and scales by the std.\n'empirical' does an empirical gaussianization (but this cannot be inverted).\n'outliers' tries to squeeze in the outliers\nAny other choice will skip the transformation.", "short_description": "Transform each marginal to be as close to a standard Gaussian as possible."}, "args": ["self", "x", "fit"], "returns": [["x"]], "min_max_lineno": {"min_lineno": 387, "max_lineno": 420}, "calls": ["linearcorex.mean_impute", "len", "cm.CUDAMatrix", "numpy.mean", "numpy.sqrt().clip", "print", "linearcorex.g", "numpy.max", "numpy.mean", "numpy.std().clip", "print", "numpy.sqrt", "numpy.abs", "numpy.array", "numpy.std", "numpy.sum", "scipy.stats.norm.ppf", "len", "scipy.stats.rankdata"], "store_vars_calls": {"self.n_obs": "len", "x": "g", "mean": "np.mean", "std": "np.std().clip"}}, "invert": {"doc": {"short_description": "Invert the preprocessing step to get x's in the original space."}, "args": ["self", "x"], "returns": [["x"]], "min_max_lineno": {"min_lineno": 421, "max_lineno": 429}, "calls": ["linearcorex.g_inv"]}, "predict": {"args": ["self", "y"], "min_max_lineno": {"min_lineno": 430, "max_lineno": 432}, "calls": ["linearcorex.Corex.invert", "numpy.dot"]}, "get_covariance": {"args": ["self"], "min_max_lineno": {"min_lineno": 433, "max_lineno": 446}, "calls": ["numpy.dot", "numpy.fill_diagonal", "numpy.einsum", "numpy.fill_diagonal"], "store_vars_calls": {"cov": "np.einsum"}}}}}, "functions": {"pick_n_hidden": {"doc": {"short_description": "A helper function to pick the number of hidden factors / clusters to use."}, "args": ["data", "repeat", "verbose"], "returns": [["all_scores"]], "min_max_lineno": {"min_lineno": 448, "max_lineno": 471}, "calls": ["range", "max", "all_scores.append", "linearcorex.Corex.fit", "scores.append", "print", "linearcorex.Corex"], "store_vars_calls": {"score": "max", "out": "Corex().fit"}}, "g": {"doc": {"short_description": "A transformation that suppresses outliers for a standard normal."}, "args": ["x", "t"], "min_max_lineno": {"min_lineno": 473, "max_lineno": 478}, "calls": ["numpy.clip", "numpy.tanh"], "store_vars_calls": {"xp": "np.clip", "diff": "np.tanh"}}, "g_inv": {"doc": {"short_description": "Inverse of g transform."}, "args": ["x", "t"], "min_max_lineno": {"min_lineno": 480, "max_lineno": 485}, "calls": ["numpy.clip", "numpy.arctanh", "numpy.clip"], "store_vars_calls": {"xp": "np.clip", "diff": "np.arctanh"}}, "mean_impute": {"doc": {"long_description": "mean value taken from the marginal distribution of that column.", "short_description": "Missing values in the data, x, are indicated by v. Wherever this value appears in x, it is replaced by the"}, "args": ["x", "v"], "min_max_lineno": {"min_lineno": 487, "max_lineno": 501}, "calls": ["enumerate", "numpy.isnan", "numpy.where", "numpy.mean", "x_new.append", "n_obs.append", "numpy.array", "numpy.where", "numpy.isfinite", "len", "numpy.array", "numpy.isnan"], "store_vars_calls": {"x": "np.where"}}, "random_impute": {"doc": {"long_description": "random value taken from the marginal distribution of that column.", "short_description": "Missing values in the data, x, are indicated by v. Wherever this value appears in x, it is replaced by a"}, "args": ["x", "v"], "min_max_lineno": {"min_lineno": 503, "max_lineno": 515}, "calls": ["enumerate", "numpy.isnan", "numpy.where", "numpy.random.choice", "x_new.append", "numpy.array", "numpy.where", "numpy.isfinite", "numpy.isnan", "len"], "store_vars_calls": {"x": "np.where"}}}, "is_test": false}