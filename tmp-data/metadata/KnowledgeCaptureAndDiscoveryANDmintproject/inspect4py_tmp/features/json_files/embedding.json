{"file": {"path": "/Users/dakixr/Desktop/github/scc/tmp-data/metadata/KnowledgeCaptureAndDiscoveryANDmintproject/byod-cleaning-api/kbclean/detection/features/embedding.py", "fileNameBase": "embedding", "extension": "py"}, "dependencies": [{"from_module": "typing", "import": "List", "type": "external"}, {"import": "torch", "type": "external"}, {"from_module": "kbclean.detection.features.base", "import": "BaseExtractor", "type": "external"}, {"from_module": "kbclean.utils.data.readers", "import": "RowBasedValue", "type": "external"}, {"from_module": "torchnlp.encoders.text.text_encoder", "import": "stack_and_pad_tensors", "type": "external"}, {"from_module": "torchtext.data.utils", "import": "get_tokenizer", "type": "external"}, {"from_module": "torchtext.vocab", "import": "FastText", "type": "external"}], "classes": {"CharFastText": {"extend": ["BaseExtractor"], "min_max_lineno": {"min_lineno": 13, "max_lineno": 27}, "methods": {"fit": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 14, "max_lineno": 16}}, "transform": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 17, "max_lineno": 22}, "calls": ["torchnlp.encoders.text.text_encoder.stack_and_pad_tensors", "fasttext.get_vecs_by_tokens", "list"]}, "n_features": {"args": ["self"], "min_max_lineno": {"min_lineno": 25, "max_lineno": 27}}}}, "CharAvgFastText": {"extend": ["BaseExtractor"], "min_max_lineno": {"min_lineno": 29, "max_lineno": 43}, "methods": {"fit": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 30, "max_lineno": 32}}, "transform": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 33, "max_lineno": 38}, "calls": ["torch.stack", "torch.mean", "fasttext.get_vecs_by_tokens", "list"]}, "n_features": {"args": ["self"], "min_max_lineno": {"min_lineno": 41, "max_lineno": 43}}}}, "WordFastText": {"extend": ["BaseExtractor"], "min_max_lineno": {"min_lineno": 45, "max_lineno": 59}, "methods": {"__init__": {"args": ["self"], "min_max_lineno": {"min_lineno": 46, "max_lineno": 48}, "calls": ["torchtext.data.utils.get_tokenizer"], "store_vars_calls": {"self.tokenizer": "get_tokenizer"}}, "fit": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 49, "max_lineno": 51}}, "transform": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 52, "max_lineno": 55}, "calls": ["torchnlp.encoders.text.text_encoder.stack_and_pad_tensors", "fasttext.get_vecs_by_tokens", "embedding.WordFastText.tokenizer"]}, "n_features": {"args": ["self"], "min_max_lineno": {"min_lineno": 57, "max_lineno": 59}}}}, "WordAvgFastText": {"extend": ["BaseExtractor"], "min_max_lineno": {"min_lineno": 61, "max_lineno": 78}, "methods": {"__init__": {"args": ["self"], "min_max_lineno": {"min_lineno": 62, "max_lineno": 64}, "calls": ["torchtext.data.utils.get_tokenizer"], "store_vars_calls": {"self.tokenizer": "get_tokenizer"}}, "fit": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 65, "max_lineno": 67}}, "transform": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 68, "max_lineno": 73}, "calls": ["torch.stack", "torch.mean", "fasttext.get_vecs_by_tokens", "embedding.WordAvgFastText.tokenizer"]}, "n_features": {"args": ["self"], "min_max_lineno": {"min_lineno": 76, "max_lineno": 78}}}}, "CoValueFastText": {"extend": ["BaseExtractor"], "min_max_lineno": {"min_lineno": 79, "max_lineno": 101}, "methods": {"__init__": {"args": ["self"], "min_max_lineno": {"min_lineno": 80, "max_lineno": 82}, "calls": ["torchtext.data.utils.get_tokenizer"], "store_vars_calls": {"self.tokenizer": "get_tokenizer"}}, "fit": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 83, "max_lineno": 85}}, "transform": {"args": ["self", "values"], "min_max_lineno": {"min_lineno": 86, "max_lineno": 96}, "calls": ["torch.stack", "torch.mean", "fasttext.get_vecs_by_tokens", "embedding.CoValueFastText.tokenizer", "list", "x.row_dict.values"]}, "n_features": {"args": ["self"], "min_max_lineno": {"min_lineno": 99, "max_lineno": 101}}}}}, "body": {"calls": ["torchtext.vocab.FastText"], "store_vars_calls": {"fasttext": "FastText"}}, "is_test": false}